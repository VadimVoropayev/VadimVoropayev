{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа №2\n",
    "по дисциплине *Data Mining и исследование данных*\n",
    "\n",
    "Вариант 4\n",
    "\n",
    "Работа выполнена **Воропаевым В.С.**, гр. **М1О-415Бки-19**\n",
    "\n",
    "Цель лабораторной работы: разработать модели для определения качества вин, подобрать гиперпараметры и сохранить их вместе с обученными моделями.\n",
    "\n",
    "Для начала сделаем pipeline для предобработки. Предобработка будет состоять из следующих этапов:\n",
    " - для всех столбцов кроме ```quality``` - привести значения к одному диапазону\n",
    " - для столбца ```quality``` - привести значения к двум классам - хорошему и плохому вину (уровень качества вина строго больше/равен или меньше 5 соответственно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "class Categorizer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):   #Определяем вино как плохое или хорошее\n",
    "        res = [1 if int(x) > 5 else 0 for x in X.values]\n",
    "        return pd.DataFrame(res)\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):   #Оставить имена колонок в исходном виде\n",
    "        return input_features\n",
    "\n",
    "StandardScaler().get_feature_names_out\n",
    "\n",
    "red_dataset = pd.read_csv('datasets/winequality-red.csv', sep=';')\n",
    "\n",
    "non_quality = [col for col in red_dataset.columns if col != 'quality']\n",
    "\n",
    "pipeline = ColumnTransformer(\n",
    "    [('category', Categorizer(), ['quality'])],\n",
    "    remainder=(StandardScaler()),    #Остальные столбцы масштабируем\n",
    "    verbose_feature_names_out=False)    #Не добавляем префикс к названиям столбцов \n",
    "pipeline.set_output(transform = 'pandas')\n",
    "\n",
    "\n",
    "red_dataset = pipeline.fit_transform(red_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В результате получаем данные в гораздо более близких диапазонах друг к другу, чем раньше. Далее, перед созданием и обучением моделей необходимо разделить датасет на тестовую и обучающую выборку, а из каждой выборки в свою очередь убрать значения качества вина, чтобы они не участвовали в процессе обучения в качестве параметра. Разделение на выборки лучше проводить с помощью ```StratifiedShuffleSplit```, чтобы выборки содержали в себе различные образцы, а не схожие (иначе модели переобучатся, и не смогут распознавать другие образцы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "red_labels = red_dataset['quality']\n",
    "red_data = red_dataset.copy().drop('quality', axis=1)\n",
    "\n",
    "str_shuf_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2022)\n",
    "for train, test in str_shuf_split.split(red_data, red_labels):\n",
    "    pass\n",
    "\n",
    "red_X_test = red_data.iloc[test]\n",
    "red_y_test = red_labels.iloc[test]\n",
    "\n",
    "red_X_train = red_data.iloc[train]\n",
    "red_y_train = red_labels.iloc[train]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично для белых вин:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>-0.081770</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>2.821349</td>\n",
       "      <td>-0.035355</td>\n",
       "      <td>0.569932</td>\n",
       "      <td>0.744565</td>\n",
       "      <td>2.331512</td>\n",
       "      <td>-1.246921</td>\n",
       "      <td>-0.349184</td>\n",
       "      <td>-1.393152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.657501</td>\n",
       "      <td>0.215896</td>\n",
       "      <td>0.048001</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>0.147747</td>\n",
       "      <td>-1.253019</td>\n",
       "      <td>-0.149685</td>\n",
       "      <td>-0.009154</td>\n",
       "      <td>0.740029</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>-0.824276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.475751</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.543838</td>\n",
       "      <td>0.100282</td>\n",
       "      <td>0.193523</td>\n",
       "      <td>-0.312141</td>\n",
       "      <td>-0.973336</td>\n",
       "      <td>0.358665</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>-0.436816</td>\n",
       "      <td>-0.336667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409125</td>\n",
       "      <td>-0.478657</td>\n",
       "      <td>-0.117278</td>\n",
       "      <td>0.415768</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.687541</td>\n",
       "      <td>1.121091</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.011480</td>\n",
       "      <td>-0.787342</td>\n",
       "      <td>-0.499203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.776015</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>-0.365197</td>\n",
       "      <td>-0.944765</td>\n",
       "      <td>-0.310008</td>\n",
       "      <td>-0.664970</td>\n",
       "      <td>-1.091000</td>\n",
       "      <td>-0.965483</td>\n",
       "      <td>0.541334</td>\n",
       "      <td>0.088973</td>\n",
       "      <td>0.557282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.301959</td>\n",
       "      <td>0.414339</td>\n",
       "      <td>0.213280</td>\n",
       "      <td>0.317179</td>\n",
       "      <td>0.056196</td>\n",
       "      <td>1.275590</td>\n",
       "      <td>0.697499</td>\n",
       "      <td>0.291789</td>\n",
       "      <td>-0.253446</td>\n",
       "      <td>-0.261553</td>\n",
       "      <td>-0.743008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.420473</td>\n",
       "      <td>-0.379435</td>\n",
       "      <td>-1.191592</td>\n",
       "      <td>-1.023637</td>\n",
       "      <td>-0.218457</td>\n",
       "      <td>-0.312141</td>\n",
       "      <td>-0.643875</td>\n",
       "      <td>-0.497350</td>\n",
       "      <td>-1.313153</td>\n",
       "      <td>-0.261553</td>\n",
       "      <td>-0.905544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.605613</td>\n",
       "      <td>0.116674</td>\n",
       "      <td>-0.282557</td>\n",
       "      <td>-1.043355</td>\n",
       "      <td>-1.088192</td>\n",
       "      <td>-0.900190</td>\n",
       "      <td>-0.667408</td>\n",
       "      <td>-1.784717</td>\n",
       "      <td>1.004955</td>\n",
       "      <td>-0.962605</td>\n",
       "      <td>1.857572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.013043</td>\n",
       "      <td>-0.677101</td>\n",
       "      <td>0.378559</td>\n",
       "      <td>-1.102508</td>\n",
       "      <td>-1.179743</td>\n",
       "      <td>-0.782580</td>\n",
       "      <td>-0.949803</td>\n",
       "      <td>-1.543962</td>\n",
       "      <td>0.475102</td>\n",
       "      <td>-1.488394</td>\n",
       "      <td>1.044891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      quality  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0         1.0       0.172097         -0.081770     0.213280        2.821349   \n",
       "1         1.0      -0.657501          0.215896     0.048001       -0.944765   \n",
       "2         1.0       1.475751          0.017452     0.543838        0.100282   \n",
       "3         1.0       0.409125         -0.478657    -0.117278        0.415768   \n",
       "4         1.0       0.409125         -0.478657    -0.117278        0.415768   \n",
       "...       ...            ...               ...          ...             ...   \n",
       "4893      1.0      -0.776015         -0.677101    -0.365197       -0.944765   \n",
       "4894      0.0      -0.301959          0.414339     0.213280        0.317179   \n",
       "4895      1.0      -0.420473         -0.379435    -1.191592       -1.023637   \n",
       "4896      1.0      -1.605613          0.116674    -0.282557       -1.043355   \n",
       "4897      1.0      -1.013043         -0.677101     0.378559       -1.102508   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\n",
       "0     -0.035355             0.569932              0.744565  2.331512   \n",
       "1      0.147747            -1.253019             -0.149685 -0.009154   \n",
       "2      0.193523            -0.312141             -0.973336  0.358665   \n",
       "3      0.559727             0.687541              1.121091  0.525855   \n",
       "4      0.559727             0.687541              1.121091  0.525855   \n",
       "...         ...                  ...                   ...       ...   \n",
       "4893  -0.310008            -0.664970             -1.091000 -0.965483   \n",
       "4894   0.056196             1.275590              0.697499  0.291789   \n",
       "4895  -0.218457            -0.312141             -0.643875 -0.497350   \n",
       "4896  -1.088192            -0.900190             -0.667408 -1.784717   \n",
       "4897  -1.179743            -0.782580             -0.949803 -1.543962   \n",
       "\n",
       "            pH  sulphates   alcohol  \n",
       "0    -1.246921  -0.349184 -1.393152  \n",
       "1     0.740029   0.001342 -0.824276  \n",
       "2     0.475102  -0.436816 -0.336667  \n",
       "3     0.011480  -0.787342 -0.499203  \n",
       "4     0.011480  -0.787342 -0.499203  \n",
       "...        ...        ...       ...  \n",
       "4893  0.541334   0.088973  0.557282  \n",
       "4894 -0.253446  -0.261553 -0.743008  \n",
       "4895 -1.313153  -0.261553 -0.905544  \n",
       "4896  1.004955  -0.962605  1.857572  \n",
       "4897  0.475102  -1.488394  1.044891  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_dataset = pd.read_csv('datasets/winequality-white.csv', sep=';')\n",
    "\n",
    "white_dataset = pipeline.fit_transform(white_dataset)\n",
    "\n",
    "white_labels = white_dataset['quality']\n",
    "white_data = white_dataset.drop('quality', axis=1)\n",
    "\n",
    "str_shuf_split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=2022)\n",
    "for train, test in str_shuf_split.split(white_data, white_labels):\n",
    "    pass\n",
    "\n",
    "white_X_test = white_data.iloc[test]\n",
    "white_y_test = white_labels.iloc[test]\n",
    "\n",
    "white_X_train = white_data.iloc[train]\n",
    "white_y_train = white_labels.iloc[train]\n",
    "\n",
    "white_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее приступим к обучению, подбору гиперпараметров, тестированию и оценке моделей. Так как шаги для каждой модели одинаковы, то будет удобнее выделмть все эти действия в одну функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red|logistic-regression\n",
      "{'clf__C': 1.0188721901979945, 'clf__tol': 0.009227130288899755} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[117  32]\n",
      " [ 44 127]]\n",
      "\n",
      "red|SVM\n",
      "{'clf__C': 1.4543183607059906, 'clf__tol': 0.0038546722586255684} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[ 54  95]\n",
      " [ 22 149]]\n",
      "\n",
      "red|KNN\n",
      "{'clf__leaf_size': 32, 'clf__n_neighbors': 6} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[106  43]\n",
      " [ 56 115]]\n",
      "\n",
      "red|naive-bayes\n",
      "{'clf__var_smoothing': 0.45070526279411205} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[111  38]\n",
      " [ 45 126]]\n",
      "\n",
      "red|random-forest\n",
      "{'clf__max_features': 'log2', 'clf__min_samples_split': 3, 'clf__n_estimators': 267} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[119  30]\n",
      " [ 30 141]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>logistic-regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>naive-bayes</th>\n",
       "      <th>random-forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.690625</td>\n",
       "      <td>0.740625</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.871345</td>\n",
       "      <td>0.672515</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.798742</td>\n",
       "      <td>0.610656</td>\n",
       "      <td>0.727848</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.824561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC curve</td>\n",
       "      <td>0.763962</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.691962</td>\n",
       "      <td>0.740904</td>\n",
       "      <td>0.811610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scores  logistic-regression       SVM       KNN  naive-bayes  \\\n",
       "0       Accuracy             0.762500  0.634375  0.690625     0.740625   \n",
       "1         Recall             0.742690  0.871345  0.672515     0.736842   \n",
       "2      Precision             0.798742  0.610656  0.727848     0.768293   \n",
       "3  ROC AUC curve             0.763962  0.616881  0.691962     0.740904   \n",
       "\n",
       "   random-forest  \n",
       "0       0.812500  \n",
       "1       0.824561  \n",
       "2       0.824561  \n",
       "3       0.811610  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, roc_auc_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "def learn_and_score(colorprefix, x_train: pd.core.frame.DataFrame, y_train: pd.core.series.Series, x_test, y_test, pipeline):\n",
    "    score = pd.DataFrame({'scores' : ['Accuracy', 'Recall', 'Precision', 'ROC AUC curve']})\n",
    "    classifiers = {         #Словарь классификаторов и их параметров\n",
    "        'logistic-regression': (LogisticRegression(solver='liblinear', max_iter=250, penalty='l2'),\n",
    "                                    {'clf__C': uniform(loc=0.01, scale=2), \n",
    "                                    'clf__tol': uniform(loc=1e-8, scale=1e-2)}),\n",
    "        'SVM':                  (SVC(kernel='linear', max_iter=250),\n",
    "                                    {'clf__C': uniform(loc=0.01, scale=2),\n",
    "                                    # 'clf__gamma': uniform(loc=0, scale=10), \n",
    "                                    # 'clf__degree': randint(2,5), \n",
    "                                    'clf__tol': uniform(loc=1e-8, scale=1e-2)}),\n",
    "        'KNN':                  (KNeighborsClassifier(algorithm='kd_tree'),\n",
    "                                    {'clf__n_neighbors': randint(3, 8), \n",
    "                                    'clf__leaf_size': randint(10, 60)}),\n",
    "        'naive-bayes':          (GaussianNB(),\n",
    "                                    {'clf__var_smoothing': uniform(loc=1e-10, scale=1)}),\n",
    "        'random-forest':        (RandomForestClassifier(random_state=2022),\n",
    "                                    {'clf__n_estimators': randint(100, 300), \n",
    "                                    'clf__max_features': ['sqrt', 'log2'],\n",
    "                                    'clf__min_samples_split': randint(2, 5)})\n",
    "    }\n",
    "\n",
    "\n",
    "    for name, values in classifiers.items():\n",
    "        clf, params = values\n",
    "        pipeline = Pipeline([\n",
    "            ('clf', clf)]\n",
    "        )\n",
    "        model = RandomizedSearchCV(pipeline, params)\n",
    "        model.fit(x_train, y_train)\n",
    "\n",
    "        with open(f\"models/{colorprefix}wine/{name}.pkl\", \"wb\") as file:\n",
    "            pickle.dump(model, file, protocol=3)\n",
    "        with open(f\"models/{colorprefix}wine/{name}.txt\", \"w\") as file:\n",
    "            file.write(str(model.best_params_))\n",
    "        print(colorprefix + '|' + name)\n",
    "        print(model.best_params_, '\\n' + '=' * 30)\n",
    "\n",
    "        y_pred = model.predict(x_test)\n",
    "        y_true = np.array(y_test)\n",
    "\n",
    "        score[name] = [accuracy_score(y_true, y_pred), recall_score(y_true, y_pred),\n",
    "                        precision_score(y_true, y_pred), roc_auc_score(y_true, y_pred)]\n",
    "\n",
    "        print(f'Confusion matrix:\\n {confusion_matrix(y_true, y_pred)}\\n')\n",
    "    return score\n",
    "\n",
    "learn_and_score('red', red_X_train, red_y_train, red_X_test, red_y_test, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white|logistic-regression\n",
      "{'clf__C': 0.40971197071721055, 'clf__tol': 0.003232279771915137} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[155 173]\n",
      " [ 87 565]]\n",
      "\n",
      "white|SVM\n",
      "{'clf__C': 0.8351398010402713, 'clf__tol': 0.00459449461206454} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[104 224]\n",
      " [147 505]]\n",
      "\n",
      "white|KNN\n",
      "{'clf__leaf_size': 52, 'clf__n_neighbors': 7} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[165 163]\n",
      " [ 93 559]]\n",
      "\n",
      "white|naive-bayes\n",
      "{'clf__var_smoothing': 0.09170029411973789} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[185 143]\n",
      " [144 508]]\n",
      "\n",
      "white|random-forest\n",
      "{'clf__max_features': 'sqrt', 'clf__min_samples_split': 3, 'clf__n_estimators': 274} \n",
      "==============================\n",
      "Confusion matrix:\n",
      " [[229  99]\n",
      " [ 64 588]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scores</th>\n",
       "      <th>logistic-regression</th>\n",
       "      <th>SVM</th>\n",
       "      <th>KNN</th>\n",
       "      <th>naive-bayes</th>\n",
       "      <th>random-forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.621429</td>\n",
       "      <td>0.738776</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.833673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.866564</td>\n",
       "      <td>0.774540</td>\n",
       "      <td>0.857362</td>\n",
       "      <td>0.779141</td>\n",
       "      <td>0.901840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.765583</td>\n",
       "      <td>0.692730</td>\n",
       "      <td>0.774238</td>\n",
       "      <td>0.780338</td>\n",
       "      <td>0.855895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ROC AUC curve</td>\n",
       "      <td>0.669563</td>\n",
       "      <td>0.545807</td>\n",
       "      <td>0.680205</td>\n",
       "      <td>0.671583</td>\n",
       "      <td>0.800006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scores  logistic-regression       SVM       KNN  naive-bayes  \\\n",
       "0       Accuracy             0.734694  0.621429  0.738776     0.707143   \n",
       "1         Recall             0.866564  0.774540  0.857362     0.779141   \n",
       "2      Precision             0.765583  0.692730  0.774238     0.780338   \n",
       "3  ROC AUC curve             0.669563  0.545807  0.680205     0.671583   \n",
       "\n",
       "   random-forest  \n",
       "0       0.833673  \n",
       "1       0.901840  \n",
       "2       0.855895  \n",
       "3       0.800006  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_and_score('white', white_X_train, white_y_train, white_X_test, white_y_test, pipeline)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге для обоих датасетов лучший результат показало применение случайного леса. С другой стороны, именно его обучение занимает больше всего времени. Для белого вина случайный лес показал лучшие результаты по всем параметрам, однако для красного метод SVM показал лучший Recall - что показывает, что модель в данной ситуации с большей вероятностью выберет правильно хорошие вина, но при этом в эту выборку могут попасть и плохие."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "999a7a36192ef33617f7408090a097317f111ceef3cec296e6063cd12c240190"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
